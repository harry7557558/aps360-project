{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torchvision\n",
    "import torch\n",
    "import os\n",
    "from os import listdir\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "# https://www.kaggle.com/datasets/yashchoudhary/realsr-v3/data\n",
    "# https://github.com/ngchc/CameraSR (City100)\n",
    "# https://github.com/xiezw5/Component-Divide-and-Conquer-for-Real-World-Image-Super-Resolution?tab=readme-ov-file\n",
    "\n",
    "# First, pick the 2000 image pairs and have two folders (train and test) and in each are 2 more folders (hr and lr). \n",
    "# .   \n",
    "# ├── train\n",
    "# │   ├── HR\n",
    "# │   └── LR\n",
    "# └── test\n",
    "#     ├── HR\n",
    "#     └── LR\n",
    "# Pre-split already, 80-20 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_IMAGES_DIR = \"./images\" # Path to your directory where the images/ folder is \n",
    "CROPPED_DATASET_IMAGES_DIR = \"./cropped_images\" # Path to an empty directory for the cropped images\n",
    "\n",
    "os.makedirs(\"{}/train/HR\".format(CROPPED_DATASET_IMAGES_DIR), exist_ok=True)\n",
    "os.makedirs(\"{}/test/HR\".format(CROPPED_DATASET_IMAGES_DIR), exist_ok=True)\n",
    "os.makedirs(\"{}/train/LR\".format(CROPPED_DATASET_IMAGES_DIR), exist_ok=True)\n",
    "os.makedirs(\"{}/test/LR\".format(CROPPED_DATASET_IMAGES_DIR), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly crop the images and store them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random crop transformation to apply\n",
    "transform = T.Compose([\n",
    "        T.RandomCrop(128)\n",
    "])\t\t\n",
    "\n",
    "directories = [\"test\", \"train\"]\n",
    "for directory in directories:\n",
    "\t# Deal with transforming both the LR and HR images at the same time in order \n",
    "\t# to transform them the same way\n",
    "\tHR_dir = sorted(os.listdir(\"{}/{}/HR\".format(DATASET_IMAGES_DIR, directory)))\n",
    "\tLR_dir = sorted(os.listdir(\"{}/{}/LR\".format(DATASET_IMAGES_DIR, directory)))\n",
    "\tfor imageIndex,img in enumerate(LR_dir):\n",
    "\n",
    "\t\timgLR = Image.open(\"{}/{}/LR/\".format(DATASET_IMAGES_DIR, directory)+LR_dir[imageIndex])\n",
    "\t\timgHR = Image.open(\"{}/{}/HR/\".format(DATASET_IMAGES_DIR, directory)+HR_dir[imageIndex])\n",
    "\n",
    "\t\t# Save the state and reload the rng state so that the same transformation is applied\n",
    "\t\t# to both images\n",
    "\t\tstate = torch.get_rng_state()\n",
    "\t\timgLR = transform(imgLR)\n",
    "\t\ttorch.set_rng_state(state)\n",
    "\t\timgHR = transform(imgHR)\n",
    "\n",
    "\t\t# Save the images in the cropped dataset folder\n",
    "\t\timgLR.save(\"{}/{}/LR/\".format(CROPPED_DATASET_IMAGES_DIR, directory)+LR_dir[imageIndex])\n",
    "\t\timgHR.save(\"{}/{}/HR/\".format(CROPPED_DATASET_IMAGES_DIR, directory)+HR_dir[imageIndex])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
